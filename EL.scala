val cities = spark.read.format("jdbc")
	.option("url", "jdbc:postgresql://########.rw.mdb.yandexcloud.net:6432/store101")
	.option("dbtable", "store.cities")
	.option("user", "########")
	.option("password", "########")
	.option("ssl", "True")
	.option("sslmode", "require" )
	.option("driver", "org.postgresql.Driver")
	.load().write.mode("overwrite").saveAsTable("store101.cities")

val customers = spark.read.format("jdbc")
	.option("url", "jdbc:postgresql://########.rw.mdb.yandexcloud.net:6432/store101")
	.option("dbtable", "store.customers")
	.option("user", "########")
	.option("password", "########")
	.option("ssl", "True")
	.option("sslmode", "require" )
	.option("driver", "org.postgresql.Driver")
	.load().write.mode("overwrite").saveAsTable("store101.customers")

val orders = spark.read.format("jdbc")
	.option("url", "jdbc:postgresql://########.rw.mdb.yandexcloud.net:6432/store101")
	.option("dbtable", "store.orders")
	.option("user", "########")
	.option("password", "########")
	.option("ssl", "True")
	.option("sslmode", "require" )
	.option("driver", "org.postgresql.Driver")
	.load().write.mode("overwrite").saveAsTable("store101.orders")

val sales = spark.read.format("jdbc")
	.option("url", "jdbc:postgresql://########.rw.mdb.yandexcloud.net:6432/store101")
	.option("dbtable", "store.sales")
	.option("user", "########")
	.option("password", "########")
	.option("ssl", "True")
	.option("sslmode", "require" )
	.option("driver", "org.postgresql.Driver")
	.load().write.mode("overwrite").saveAsTable("store101.sales")

val products = spark.read.format("jdbc")
	.option("url", "jdbc:postgresql://########.rw.mdb.yandexcloud.net:6432/store101")
	.option("dbtable", "store.products")
	.option("user", "########")
	.option("password", "########")
	.option("ssl", "True")
	.option("sslmode", "require" )
	.option("driver", "org.postgresql.Driver")
	.load().write.mode("overwrite").saveAsTable("store101.products")

val cities = spark.table("store101.cities").select(col("city_id").as("c_city_id"), col("city_name"), col("country"), col("region"))

val products = spark.table("store101.products").select(col("product_id").as("p_product_id"), col("category"), col("sub_category"), col("product_name"))
 
val customers = spark.table("store101.customers").select(col("customer_id").as("c_customer_id"), col("city_id").as("cus_city_id"), col("customer_name"), col("segment")) 

val orders = spark.table("store101.orders").select(col("order_id").as("o_order_id"), col("customer_id").as("o_customer_id"), col("order_date"), col("ship_date"), col("order_priority")) 

val sales = spark.table("store101.sales").select(col("product_id").as("s_product_id"), col("order_id").as("s_order_id"), col("sale_id"), col("quantity"), col("sales"), col("profit"))
